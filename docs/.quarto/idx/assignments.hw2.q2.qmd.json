{"title":"Question 2","markdown":{"yaml":{"format":{"html":{"toc":true,"toc-depth":3,"theme":"cosmo","number-sections":false,"output-file":"assignments.hw2.q2.html"}},"fontsize":"0.9em","code-block-background":true,"include-in-header":{"text":"<link rel = \"icon\" href = \"data:,\" />"},"toc-title-numbers":false,"number-depth":0},"headingText":"Question 2","containsRefs":false,"markdown":"\n<style></style><style>.printedClojure .sourceCode {\n  background-color: transparent;\n  border-style: none;\n}\n</style><style>.clay-limit-image-width .clay-image {max-width: 100%}\n.clay-side-by-side .sourceCode {margin: 0}\n.clay-side-by-side {margin: 1em 0}\n</style>\n<script src=\"assignments.hw2.q2_files/md-default1.js\" type=\"text/javascript\"></script><script src=\"assignments.hw2.q2_files/md-default2.js\" type=\"text/javascript\"></script><script src=\"assignments.hw2.q2_files/vega3.js\" type=\"text/javascript\"></script><script src=\"assignments.hw2.q2_files/vega4.js\" type=\"text/javascript\"></script><script src=\"assignments.hw2.q2_files/vega5.js\" type=\"text/javascript\"></script>\n\n::: {.sourceClojure}\n```clojure\n(ns assignments.hw2.q2\n  (:require\n   [assignments.hw2.utils :refer :all]\n   ;; [scicloj.sklearn-clj]\n   [scicloj.hanamicloth.v1.api :as haclo]\n   [libpython-clj2.python :refer [py. py.-]]\n   [libpython-clj2.require :refer [require-python]]\n   [my-py-clj.config :refer :all]\n   [tablecloth.api :as tc]\n   [scicloj.kindly.v4.kind :as kind]))\n```\n:::\n\n\n---\n\n#### *Q2: Cross Validation for Ridge Regression (40 points)*\n\nFor this question, you will need to perform Ridge ($L^2$) regression with K-fold cross validation via Scki-Learn. The data set is the famous Boston Housing data, which is a benchmark data for regression. The data contains 14 attributes and the `medv`, median value of owner-occupied homes in $1000s, will be your target to predict. The data set can be downloaded from canvas. You can also find some helpful information at [Kaggle](https://www.kaggle.com/code/henriqueyamahata/boston-housing-with-linear-regression/notebook). \n  \n  In lecture, we learned training, test, and validation. However, in the real-world, we cannot always afford to implement it due to insufficient data. An alternative solution is K-fold cross validation which uses a part of the available data to fit the model, and a different part to test it. K-fold CV procedure splits the data into K equal-sized parts.\n\n***1) Load the train data and test data***\n\n\n::: {.sourceClojure}\n```clojure\n(require-python '[numpy :as np])\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n:ok\n\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(require-python '[pandas :as pd])\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n:ok\n\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(require-python '[sklearn.model_selection :as model-selection])\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n:ok\n\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(require-python '[sklearn.linear_model :as linear-model])\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n:ok\n\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(require-python '[sklearn.metrics :as metrics])\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n:ok\n\n```\n:::\n\n\nThese lines import necessary Python libraries for data manipulation, model selection, and evaluation. I wish I hide the `:ok` code-outputs, alas, I haven't found that option yet.\n\n\n::: {.sourceClojure}\n```clojure\n(def train-data (pd/read_csv \"data/A1Q2_Train_Data.csv\"))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(def test-data (pd/read_csv \"data/A1Q2_Test_Data.csv\"))\n```\n:::\n\n\nHere we load the training and test datasets from CSV files using pandas.\n\n\n::: {.sourceClojure}\n```clojure\n(pd/DataFrame train-data)\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n      ID     crim    zn  indus  chas  ...  tax  ptratio   black  lstat  medv\n0      1  0.00632  18.0   2.31     0  ...  296     15.3  396.90   4.98  24.0\n1      2  0.02731   0.0   7.07     0  ...  242     17.8  396.90   9.14  21.6\n2      4  0.03237   0.0   2.18     0  ...  222     18.7  394.63   2.94  33.4\n3      5  0.06905   0.0   2.18     0  ...  222     18.7  396.90   5.33  36.2\n4      7  0.08829  12.5   7.87     0  ...  311     15.2  395.60  12.43  22.9\n..   ...      ...   ...    ...   ...  ...  ...      ...     ...    ...   ...\n328  500  0.17783   0.0   9.69     0  ...  391     19.2  395.77  15.10  17.5\n329  502  0.06263   0.0  11.93     0  ...  273     21.0  391.99   9.67  22.4\n330  503  0.04527   0.0  11.93     0  ...  273     21.0  396.90   9.08  20.6\n331  504  0.06076   0.0  11.93     0  ...  273     21.0  396.90   5.64  23.9\n332  506  0.04741   0.0  11.93     0  ...  273     21.0  396.90   7.88  11.9\n\n[333 rows x 15 columns]\n\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(pd/DataFrame test-data)\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n      ID     crim    zn  indus  chas  ...  rad  tax  ptratio   black  lstat\n0      3  0.02729   0.0   7.07     0  ...    2  242     17.8  392.83   4.03\n1      6  0.02985   0.0   2.18     0  ...    3  222     18.7  394.12   5.21\n2      8  0.14455  12.5   7.87     0  ...    5  311     15.2  396.90  19.15\n3      9  0.21124  12.5   7.87     0  ...    5  311     15.2  386.63  29.93\n4     10  0.17004  12.5   7.87     0  ...    5  311     15.2  386.71  17.10\n..   ...      ...   ...    ...   ...  ...  ...  ...      ...     ...    ...\n168  496  0.17899   0.0   9.69     0  ...    6  391     19.2  393.29  17.60\n169  497  0.28960   0.0   9.69     0  ...    6  391     19.2  396.90  21.14\n170  499  0.23912   0.0   9.69     0  ...    6  391     19.2  396.90  12.92\n171  501  0.22438   0.0   9.69     0  ...    6  391     19.2  396.90  14.33\n172  505  0.10959   0.0  11.93     0  ...    1  273     21.0  393.45   6.48\n\n[173 rows x 14 columns]\n\n```\n:::\n\n\nInspect the loaded datasets as pandas DataFrames.\n\n\n::: {.sourceClojure}\n```clojure\n(def X-train (py. train-data drop \"medv\" :axis 1))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(def y-train (py. train-data \"get\" \"medv\"))\n```\n:::\n\n\nWe separate the features (X-train) and target variable (y-train) from the training data.\n\n***2) Perform Ridge regression on the train data***\n\n\n::: {.sourceClojure}\n```clojure\n(def ridge-model (linear-model/Ridge))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(def param-grid {\"alpha\" [150 160 165 170 175 180 185 190 195 200]})\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(def cv-ridge (model-selection/GridSearchCV ridge-model param-grid :cv 5))\n```\n:::\n\n\nHere we set up the Ridge regression model and define a parameter grid for alpha values. We then create a GridSearchCV object for 5-fold cross-validation.\n\n\n::: {.sourceClojure}\n```clojure\n(py. cv-ridge fit X-train y-train)\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\nGridSearchCV(cv=5, estimator=Ridge(),\n             param_grid={'alpha': [150, 160, 165, 170, 175, 180, 185, 190, 195,\n                                   200]})\n\n```\n:::\n\n\nThis line fits the Ridge regression model using GridSearchCV on the training data.\n\n\n::: {.sourceClojure}\n```clojure\n(answer (str \"Best parameters:\" (py.- cv-ridge best_params_)))\n```\n:::\n\n\n> <span style=\"color: black; font-size: 1.5em;\">**Best parameters:{'alpha': 180}**</span>\n\n\n::: {.sourceClojure}\n```clojure\n(answer (str \"Best CV score:\" (py.- cv-ridge best_score_)))\n```\n:::\n\n\n> <span style=\"color: black; font-size: 1.5em;\">**Best CV score:0.17820256573782292**</span>\n\n### K-fold Cross Validation Procedure:\n\n1) The training data is divided into 5 equal parts (folds).\n2) For each fold:\n\n   a) That fold is treated as a validation set.\n   b) The model is trained on the remaining 4 folds.\n   c) The model's performance is evaluated on the validation fold.\n\n3) This process is repeated 5 times, with each fold serving as the validation set once.\n4) The average performance across all 5 validations is used as the cross-validation score.\n5) This entire procedure is repeated for each hyperparameter combination (different alpha values).\n6) The hyperparameters that yield the best average performance are selected.\n\n This method provides a robust estimate of the model's performance and helps in selecting the best hyperparameters, reducing the risk of overfitting.\n\nBelow, we print the best model's intercept and coefficients, and construct a human-readable equation for the Ridge regression model.\n\n\n::: {.sourceClojure}\n```clojure\n(let [best-model (py.- cv-ridge best_estimator_)\n      intercept (py.- best-model intercept_)\n      coefficients (py.- best-model coef_)\n      feature-names (py.- X-train columns)]\n  (answer\n   (str \"Ridge Regression Equation:\\n\"\n        \"$medv = \"\n        (format \"%.4f\" intercept)\n        (apply str\n               (map (fn [name coef]\n                      (format \" %s %.4f * %s\"\n                              (if (pos? coef) \"+\" \"-\")\n                              (Math/abs coef)\n                              name))\n                    feature-names\n                    coefficients)) \"$\")))\n```\n:::\n\n\n> <span style=\"color: black; font-size: 1.5em;\">**Ridge Regression Equation:\n$medv = 39.8963 - 0.0023 * ID - 0.0490 * crim + 0.0578 * zn + 0.0043 * indus + 0.3847 * chas - 0.0680 * nox + 1.3832 * rm + 0.0129 * age - 0.9845 * dis + 0.3697 * rad - 0.0167 * tax - 0.7580 * ptratio + 0.0116 * black - 0.7889 * lstat$**</span>\n\n***3) Justify the choice of K***\n\nWe chose $K=5$ for cross-validation as it provides a good balance between bias and variance. It's a common choice that works well for most datasets, offering reliable performance estimates without excessive computational cost.\n\n***4) Test the model on the test data***\n\n\n::: {.sourceClojure}\n```clojure\n(def best-ridge-model (py.- cv-ridge best_estimator_))\n```\n:::\n\n\nHere we extract the best Ridge regression model from the GridSearchCV results.\n\n\n::: {.sourceClojure}\n```clojure\n(def y-pred (py. best-ridge-model predict test-data))\n```\n:::\n\n\n`y-pred` is the predictions on the entire test dataset using the best Ridge regression model.\n\n***5) Analyze the importance of each feature and justify your results in the report***\n\n\n::: {.sourceClojure}\n```clojure\n(def feature-importance (py.- best-ridge-model coef_))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(def feature-names (py.- X-train columns))\n```\n:::\n\n\nThese lines extract the feature coefficients (which represent feature importance in linear models) and feature names from the best model and training data, respectively.\n\n\n::: {.sourceClojure}\n```clojure\n(let [feature-names (vec feature-names)\n      feature-importance (vec feature-importance)\n      data (tc/dataset {:vars feature-names\n                        :importance feature-importance})\n      sorted (tc/order-by data :importance :desc)]\n  (-> sorted\n      (haclo/layer-bar\n       {:=y :vars :=x :importance       ;order-by??\n        :=title \"Feature Importances\"})))\n```\n:::\n\n\n\n```{=html}\n<div><script>vegaEmbed(document.currentScript.parentElement, {\"encoding\":{\"x\":{\"field\":\"x\",\"type\":\"nominal\"},\"y\":{\"field\":\"y\",\"type\":\"nominal\"}},\"usermeta\":{\"embedOptions\":{\"renderer\":\"svg\"}},\"width\":400,\"background\":\"floralwhite\",\"layer\":[{\"mark\":{\"type\":\"bar\",\"tooltip\":true},\"encoding\":{\"x\":{\"field\":\"importance\",\"type\":\"quantitative\"},\"y\":{\"field\":\"vars\",\"type\":\"nominal\"}},\"data\":{\"values\":\"vars,importance\\nrm,1.3832310453542689\\nchas,0.3846674322920127\\nrad,0.3697238002007228\\nzn,0.05778196417719924\\nage,0.012925702145975593\\nblack,0.011621283571712876\\nindus,0.004296184605311984\\nID,-0.002269139274071281\\ntax,-0.016673829625451803\\ncrim,-0.049041726989618964\\nnox,-0.06800806864610484\\nptratio,-0.7579591504170874\\nlstat,-0.7888725000106315\\ndis,-0.984478760041314\\n\",\"format\":{\"type\":\"csv\"}}}],\"height\":300,\"data\":{\"url\":\"assignments.hw2.q2_files\\/0.csv\",\"format\":{\"type\":\"csv\"}}});</script></div>\n```\n\n\nThe barplot shows the regressor coefficients, which are proportional to the feature importances. The plot is generated using the Hanami plotting library.\n\n\n::: {.sourceClojure}\n```clojure\n(answer\n (str \"Feature importances:\\n\"\n      (clojure.string/join \"\\n\"\n                           (for [[feature importance] (map vector feature-names feature-importance)]\n                             (format \"%-20s : %.4f ;  \" feature importance)))))\n```\n:::\n\n\n> <span style=\"color: black; font-size: 1.5em;\">**Feature importances:\nID                   : -0.0023 ;  \ncrim                 : -0.0490 ;  \nzn                   : 0.0578 ;  \nindus                : 0.0043 ;  \nchas                 : 0.3847 ;  \nnox                  : -0.0680 ;  \nrm                   : 1.3832 ;  \nage                  : 0.0129 ;  \ndis                  : -0.9845 ;  \nrad                  : 0.3697 ;  \ntax                  : -0.0167 ;  \nptratio              : -0.7580 ;  \nblack                : 0.0116 ;  \nlstat                : -0.7889 ;  **</span>\n\nThis generates a formatted string output of all feature importances, aligning feature names and their corresponding importance values.\n\nSort features by absolute importance\n\n\n::: {.sourceClojure}\n```clojure\n(def sorted-features\n  (->> (map vector feature-names feature-importance)\n       (sort-by #(Math/abs (second %)))\n       reverse))\n```\n:::\n\n\nThis code sorts the features by the absolute value of their importance (coefficient magnitude) in descending order. This is useful because both large positive and large negative coefficients indicate important features in linear models.\n\nFinally, this code outputs a formatted string of the top 5 most important features based on the absolute value of their coefficients. This provides a quick summary of which features have the largest impact on the model's predictions.\n\n\n::: {.sourceClojure}\n```clojure\n(answer\n (str \"\\nTop 5 most important features:\\n\"\n      (clojure.string/join \"\\n\"\n                           (for [[feature importance] (take 5 sorted-features)]\n                             (format \"%-20s : %.4f ;  \" feature (float importance))))))\n```\n:::\n\n\n> <span style=\"color: black; font-size: 1.5em;\">**\nTop 5 most important features:\nrm                   : 1.3832 ;  \ndis                  : -0.9845 ;  \nlstat                : -0.7889 ;  \nptratio              : -0.7580 ;  \nchas                 : 0.3847 ;  **</span>\n\n### Explanation of feature importances:\n \n1. The most important features are those with the largest absolute coefficient values.\n2. Positive coefficients indicate that an increase in the feature leads to an increase in the predicted house price, while negative coefficients indicate the opposite.\n3. The magnitude of the coefficient represents the feature's relative importance in predicting the house price.\n4. Features with near-zero coefficients have little impact on the prediction.\n\nThis analysis helps us understand which factors most strongly influence house prices in the Boston housing dataset.\n\n\n```{=html}\n<div style=\"background-color:grey;height:2px;width:100%;\"></div>\n```\n\n\n\n```{=html}\n<div></div>\n```\n","srcMarkdownNoYaml":"\n<style></style><style>.printedClojure .sourceCode {\n  background-color: transparent;\n  border-style: none;\n}\n</style><style>.clay-limit-image-width .clay-image {max-width: 100%}\n.clay-side-by-side .sourceCode {margin: 0}\n.clay-side-by-side {margin: 1em 0}\n</style>\n<script src=\"assignments.hw2.q2_files/md-default1.js\" type=\"text/javascript\"></script><script src=\"assignments.hw2.q2_files/md-default2.js\" type=\"text/javascript\"></script><script src=\"assignments.hw2.q2_files/vega3.js\" type=\"text/javascript\"></script><script src=\"assignments.hw2.q2_files/vega4.js\" type=\"text/javascript\"></script><script src=\"assignments.hw2.q2_files/vega5.js\" type=\"text/javascript\"></script>\n\n::: {.sourceClojure}\n```clojure\n(ns assignments.hw2.q2\n  (:require\n   [assignments.hw2.utils :refer :all]\n   ;; [scicloj.sklearn-clj]\n   [scicloj.hanamicloth.v1.api :as haclo]\n   [libpython-clj2.python :refer [py. py.-]]\n   [libpython-clj2.require :refer [require-python]]\n   [my-py-clj.config :refer :all]\n   [tablecloth.api :as tc]\n   [scicloj.kindly.v4.kind :as kind]))\n```\n:::\n\n\n## Question 2\n---\n\n#### *Q2: Cross Validation for Ridge Regression (40 points)*\n\nFor this question, you will need to perform Ridge ($L^2$) regression with K-fold cross validation via Scki-Learn. The data set is the famous Boston Housing data, which is a benchmark data for regression. The data contains 14 attributes and the `medv`, median value of owner-occupied homes in $1000s, will be your target to predict. The data set can be downloaded from canvas. You can also find some helpful information at [Kaggle](https://www.kaggle.com/code/henriqueyamahata/boston-housing-with-linear-regression/notebook). \n  \n  In lecture, we learned training, test, and validation. However, in the real-world, we cannot always afford to implement it due to insufficient data. An alternative solution is K-fold cross validation which uses a part of the available data to fit the model, and a different part to test it. K-fold CV procedure splits the data into K equal-sized parts.\n\n***1) Load the train data and test data***\n\n\n::: {.sourceClojure}\n```clojure\n(require-python '[numpy :as np])\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n:ok\n\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(require-python '[pandas :as pd])\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n:ok\n\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(require-python '[sklearn.model_selection :as model-selection])\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n:ok\n\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(require-python '[sklearn.linear_model :as linear-model])\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n:ok\n\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(require-python '[sklearn.metrics :as metrics])\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n:ok\n\n```\n:::\n\n\nThese lines import necessary Python libraries for data manipulation, model selection, and evaluation. I wish I hide the `:ok` code-outputs, alas, I haven't found that option yet.\n\n\n::: {.sourceClojure}\n```clojure\n(def train-data (pd/read_csv \"data/A1Q2_Train_Data.csv\"))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(def test-data (pd/read_csv \"data/A1Q2_Test_Data.csv\"))\n```\n:::\n\n\nHere we load the training and test datasets from CSV files using pandas.\n\n\n::: {.sourceClojure}\n```clojure\n(pd/DataFrame train-data)\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n      ID     crim    zn  indus  chas  ...  tax  ptratio   black  lstat  medv\n0      1  0.00632  18.0   2.31     0  ...  296     15.3  396.90   4.98  24.0\n1      2  0.02731   0.0   7.07     0  ...  242     17.8  396.90   9.14  21.6\n2      4  0.03237   0.0   2.18     0  ...  222     18.7  394.63   2.94  33.4\n3      5  0.06905   0.0   2.18     0  ...  222     18.7  396.90   5.33  36.2\n4      7  0.08829  12.5   7.87     0  ...  311     15.2  395.60  12.43  22.9\n..   ...      ...   ...    ...   ...  ...  ...      ...     ...    ...   ...\n328  500  0.17783   0.0   9.69     0  ...  391     19.2  395.77  15.10  17.5\n329  502  0.06263   0.0  11.93     0  ...  273     21.0  391.99   9.67  22.4\n330  503  0.04527   0.0  11.93     0  ...  273     21.0  396.90   9.08  20.6\n331  504  0.06076   0.0  11.93     0  ...  273     21.0  396.90   5.64  23.9\n332  506  0.04741   0.0  11.93     0  ...  273     21.0  396.90   7.88  11.9\n\n[333 rows x 15 columns]\n\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(pd/DataFrame test-data)\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n      ID     crim    zn  indus  chas  ...  rad  tax  ptratio   black  lstat\n0      3  0.02729   0.0   7.07     0  ...    2  242     17.8  392.83   4.03\n1      6  0.02985   0.0   2.18     0  ...    3  222     18.7  394.12   5.21\n2      8  0.14455  12.5   7.87     0  ...    5  311     15.2  396.90  19.15\n3      9  0.21124  12.5   7.87     0  ...    5  311     15.2  386.63  29.93\n4     10  0.17004  12.5   7.87     0  ...    5  311     15.2  386.71  17.10\n..   ...      ...   ...    ...   ...  ...  ...  ...      ...     ...    ...\n168  496  0.17899   0.0   9.69     0  ...    6  391     19.2  393.29  17.60\n169  497  0.28960   0.0   9.69     0  ...    6  391     19.2  396.90  21.14\n170  499  0.23912   0.0   9.69     0  ...    6  391     19.2  396.90  12.92\n171  501  0.22438   0.0   9.69     0  ...    6  391     19.2  396.90  14.33\n172  505  0.10959   0.0  11.93     0  ...    1  273     21.0  393.45   6.48\n\n[173 rows x 14 columns]\n\n```\n:::\n\n\nInspect the loaded datasets as pandas DataFrames.\n\n\n::: {.sourceClojure}\n```clojure\n(def X-train (py. train-data drop \"medv\" :axis 1))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(def y-train (py. train-data \"get\" \"medv\"))\n```\n:::\n\n\nWe separate the features (X-train) and target variable (y-train) from the training data.\n\n***2) Perform Ridge regression on the train data***\n\n\n::: {.sourceClojure}\n```clojure\n(def ridge-model (linear-model/Ridge))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(def param-grid {\"alpha\" [150 160 165 170 175 180 185 190 195 200]})\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(def cv-ridge (model-selection/GridSearchCV ridge-model param-grid :cv 5))\n```\n:::\n\n\nHere we set up the Ridge regression model and define a parameter grid for alpha values. We then create a GridSearchCV object for 5-fold cross-validation.\n\n\n::: {.sourceClojure}\n```clojure\n(py. cv-ridge fit X-train y-train)\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\nGridSearchCV(cv=5, estimator=Ridge(),\n             param_grid={'alpha': [150, 160, 165, 170, 175, 180, 185, 190, 195,\n                                   200]})\n\n```\n:::\n\n\nThis line fits the Ridge regression model using GridSearchCV on the training data.\n\n\n::: {.sourceClojure}\n```clojure\n(answer (str \"Best parameters:\" (py.- cv-ridge best_params_)))\n```\n:::\n\n\n> <span style=\"color: black; font-size: 1.5em;\">**Best parameters:{'alpha': 180}**</span>\n\n\n::: {.sourceClojure}\n```clojure\n(answer (str \"Best CV score:\" (py.- cv-ridge best_score_)))\n```\n:::\n\n\n> <span style=\"color: black; font-size: 1.5em;\">**Best CV score:0.17820256573782292**</span>\n\n### K-fold Cross Validation Procedure:\n\n1) The training data is divided into 5 equal parts (folds).\n2) For each fold:\n\n   a) That fold is treated as a validation set.\n   b) The model is trained on the remaining 4 folds.\n   c) The model's performance is evaluated on the validation fold.\n\n3) This process is repeated 5 times, with each fold serving as the validation set once.\n4) The average performance across all 5 validations is used as the cross-validation score.\n5) This entire procedure is repeated for each hyperparameter combination (different alpha values).\n6) The hyperparameters that yield the best average performance are selected.\n\n This method provides a robust estimate of the model's performance and helps in selecting the best hyperparameters, reducing the risk of overfitting.\n\nBelow, we print the best model's intercept and coefficients, and construct a human-readable equation for the Ridge regression model.\n\n\n::: {.sourceClojure}\n```clojure\n(let [best-model (py.- cv-ridge best_estimator_)\n      intercept (py.- best-model intercept_)\n      coefficients (py.- best-model coef_)\n      feature-names (py.- X-train columns)]\n  (answer\n   (str \"Ridge Regression Equation:\\n\"\n        \"$medv = \"\n        (format \"%.4f\" intercept)\n        (apply str\n               (map (fn [name coef]\n                      (format \" %s %.4f * %s\"\n                              (if (pos? coef) \"+\" \"-\")\n                              (Math/abs coef)\n                              name))\n                    feature-names\n                    coefficients)) \"$\")))\n```\n:::\n\n\n> <span style=\"color: black; font-size: 1.5em;\">**Ridge Regression Equation:\n$medv = 39.8963 - 0.0023 * ID - 0.0490 * crim + 0.0578 * zn + 0.0043 * indus + 0.3847 * chas - 0.0680 * nox + 1.3832 * rm + 0.0129 * age - 0.9845 * dis + 0.3697 * rad - 0.0167 * tax - 0.7580 * ptratio + 0.0116 * black - 0.7889 * lstat$**</span>\n\n***3) Justify the choice of K***\n\nWe chose $K=5$ for cross-validation as it provides a good balance between bias and variance. It's a common choice that works well for most datasets, offering reliable performance estimates without excessive computational cost.\n\n***4) Test the model on the test data***\n\n\n::: {.sourceClojure}\n```clojure\n(def best-ridge-model (py.- cv-ridge best_estimator_))\n```\n:::\n\n\nHere we extract the best Ridge regression model from the GridSearchCV results.\n\n\n::: {.sourceClojure}\n```clojure\n(def y-pred (py. best-ridge-model predict test-data))\n```\n:::\n\n\n`y-pred` is the predictions on the entire test dataset using the best Ridge regression model.\n\n***5) Analyze the importance of each feature and justify your results in the report***\n\n\n::: {.sourceClojure}\n```clojure\n(def feature-importance (py.- best-ridge-model coef_))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(def feature-names (py.- X-train columns))\n```\n:::\n\n\nThese lines extract the feature coefficients (which represent feature importance in linear models) and feature names from the best model and training data, respectively.\n\n\n::: {.sourceClojure}\n```clojure\n(let [feature-names (vec feature-names)\n      feature-importance (vec feature-importance)\n      data (tc/dataset {:vars feature-names\n                        :importance feature-importance})\n      sorted (tc/order-by data :importance :desc)]\n  (-> sorted\n      (haclo/layer-bar\n       {:=y :vars :=x :importance       ;order-by??\n        :=title \"Feature Importances\"})))\n```\n:::\n\n\n\n```{=html}\n<div><script>vegaEmbed(document.currentScript.parentElement, {\"encoding\":{\"x\":{\"field\":\"x\",\"type\":\"nominal\"},\"y\":{\"field\":\"y\",\"type\":\"nominal\"}},\"usermeta\":{\"embedOptions\":{\"renderer\":\"svg\"}},\"width\":400,\"background\":\"floralwhite\",\"layer\":[{\"mark\":{\"type\":\"bar\",\"tooltip\":true},\"encoding\":{\"x\":{\"field\":\"importance\",\"type\":\"quantitative\"},\"y\":{\"field\":\"vars\",\"type\":\"nominal\"}},\"data\":{\"values\":\"vars,importance\\nrm,1.3832310453542689\\nchas,0.3846674322920127\\nrad,0.3697238002007228\\nzn,0.05778196417719924\\nage,0.012925702145975593\\nblack,0.011621283571712876\\nindus,0.004296184605311984\\nID,-0.002269139274071281\\ntax,-0.016673829625451803\\ncrim,-0.049041726989618964\\nnox,-0.06800806864610484\\nptratio,-0.7579591504170874\\nlstat,-0.7888725000106315\\ndis,-0.984478760041314\\n\",\"format\":{\"type\":\"csv\"}}}],\"height\":300,\"data\":{\"url\":\"assignments.hw2.q2_files\\/0.csv\",\"format\":{\"type\":\"csv\"}}});</script></div>\n```\n\n\nThe barplot shows the regressor coefficients, which are proportional to the feature importances. The plot is generated using the Hanami plotting library.\n\n\n::: {.sourceClojure}\n```clojure\n(answer\n (str \"Feature importances:\\n\"\n      (clojure.string/join \"\\n\"\n                           (for [[feature importance] (map vector feature-names feature-importance)]\n                             (format \"%-20s : %.4f ;  \" feature importance)))))\n```\n:::\n\n\n> <span style=\"color: black; font-size: 1.5em;\">**Feature importances:\nID                   : -0.0023 ;  \ncrim                 : -0.0490 ;  \nzn                   : 0.0578 ;  \nindus                : 0.0043 ;  \nchas                 : 0.3847 ;  \nnox                  : -0.0680 ;  \nrm                   : 1.3832 ;  \nage                  : 0.0129 ;  \ndis                  : -0.9845 ;  \nrad                  : 0.3697 ;  \ntax                  : -0.0167 ;  \nptratio              : -0.7580 ;  \nblack                : 0.0116 ;  \nlstat                : -0.7889 ;  **</span>\n\nThis generates a formatted string output of all feature importances, aligning feature names and their corresponding importance values.\n\nSort features by absolute importance\n\n\n::: {.sourceClojure}\n```clojure\n(def sorted-features\n  (->> (map vector feature-names feature-importance)\n       (sort-by #(Math/abs (second %)))\n       reverse))\n```\n:::\n\n\nThis code sorts the features by the absolute value of their importance (coefficient magnitude) in descending order. This is useful because both large positive and large negative coefficients indicate important features in linear models.\n\nFinally, this code outputs a formatted string of the top 5 most important features based on the absolute value of their coefficients. This provides a quick summary of which features have the largest impact on the model's predictions.\n\n\n::: {.sourceClojure}\n```clojure\n(answer\n (str \"\\nTop 5 most important features:\\n\"\n      (clojure.string/join \"\\n\"\n                           (for [[feature importance] (take 5 sorted-features)]\n                             (format \"%-20s : %.4f ;  \" feature (float importance))))))\n```\n:::\n\n\n> <span style=\"color: black; font-size: 1.5em;\">**\nTop 5 most important features:\nrm                   : 1.3832 ;  \ndis                  : -0.9845 ;  \nlstat                : -0.7889 ;  \nptratio              : -0.7580 ;  \nchas                 : 0.3847 ;  **</span>\n\n### Explanation of feature importances:\n \n1. The most important features are those with the largest absolute coefficient values.\n2. Positive coefficients indicate that an increase in the feature leads to an increase in the predicted house price, while negative coefficients indicate the opposite.\n3. The magnitude of the coefficient represents the feature's relative importance in predicting the house price.\n4. Features with near-zero coefficients have little impact on the prediction.\n\nThis analysis helps us understand which factors most strongly influence house prices in the Boston housing dataset.\n\n\n```{=html}\n<div style=\"background-color:grey;height:2px;width:100%;\"></div>\n```\n\n\n\n```{=html}\n<div></div>\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":3,"number-sections":false,"include-in-header":{"text":"<link rel = \"icon\" href = \"data:,\" />"},"output-file":"assignments.hw2.q2.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","theme":"cosmo","fontsize":"0.9em","code-block-background":true,"toc-title-numbers":false,"number-depth":0},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html","revealjs"]}