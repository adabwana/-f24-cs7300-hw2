{"title":"Question 1","markdown":{"yaml":{"format":{"html":{"toc":true,"toc-depth":3,"theme":"cosmo","number-sections":false,"output-file":"assignments.hw2.q1.html"}},"fontsize":"0.9em","code-block-background":true,"include-in-header":{"text":"<link rel = \"icon\" href = \"data:,\" />"},"toc-title-numbers":false,"number-depth":0},"headingText":"Question 1","containsRefs":false,"markdown":"\n<style></style><style>.printedClojure .sourceCode {\n  background-color: transparent;\n  border-style: none;\n}\n</style><style>.clay-limit-image-width .clay-image {max-width: 100%}\n.clay-side-by-side .sourceCode {margin: 0}\n.clay-side-by-side {margin: 1em 0}\n</style>\n<script src=\"assignments.hw2.q1_files/md-default3.js\" type=\"text/javascript\"></script><script src=\"assignments.hw2.q1_files/md-default4.js\" type=\"text/javascript\"></script><script src=\"assignments.hw2.q1_files/vega5.js\" type=\"text/javascript\"></script><script src=\"assignments.hw2.q1_files/vega6.js\" type=\"text/javascript\"></script><script src=\"assignments.hw2.q1_files/vega7.js\" type=\"text/javascript\"></script>\n\n::: {.sourceClojure}\n```clojure\n(ns assignments.hw2.q1\n  (:require\n   [my-py-clj.config :refer :all]\n   [assignments.hw2.utils :refer :all]\n   [fastmath.stats :as stats]\n  ;;  [libpython-clj2.python :refer [py.-]]\n  ;;  [scicloj.sklearn-clj.metamorph :as sklearn-mm]\n   [scicloj.hanamicloth.v1.api :as haclo]\n   [scicloj.metamorph.core :as morph]\n   [scicloj.metamorph.ml :as mm]\n   [scicloj.metamorph.ml.classification :as mlc]\n   [scicloj.metamorph.ml.gridsearch :as grid]\n   [scicloj.metamorph.ml.loss :as loss]\n   [scicloj.sklearn-clj :as sklearn-clj]\n   [scicloj.sklearn-clj.ml]                                ;; registers all models\n   [tablecloth.api :as tc]\n   [tech.v3.dataset.metamorph :as dsm]\n   [tech.v3.dataset.modelling :as ds-mod]))\n```\n:::\n\n\n---\n\n#### *Q1: Classification with Nearest Neighbor (30 Points)*\n\nFor this question, you will need to perform KNN on the famous Iris data set. You are required to use Scki-learn to completion this question. The data is stored in a csv file and it can be downloaded from Canvas. For the description of the data set, you can visit: [Wikipedia iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n\n***1) Load the data and split it into train, valid, and test (70/20/10).***\n\n\n::: {.sourceClojure}\n```clojure\n(defonce iris (-> \"data/A1Q1_Data.csv\"\n                  (tc/dataset {:key-fn (fn [colname]\n                                         (-> colname    ;kabab-case keyword\n                                             (clojure.string/replace #\"\\.|\\s\" \"-\")\n                                             clojure.string/lower-case\n                                             keyword))})\n                  (ds-mod/set-inference-target :variety)))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(def response :variety)\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(def regressors\n  (tc/column-names iris (complement #{response})))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(let [data (-> iris\n               (tc/split->seq :holdout {:seed 123 :ratio 0.9}))\n      test-data (-> data first :test)\n      train-val-data (-> data first :train\n                         (tc/split->seq :holdout {:seed 123}))\n      train-data (-> train-val-data first :train)\n      val-data (-> train-val-data first :test)]\n  (def test-data test-data)\n  (def train-data train-data)\n  (def val-data val-data))\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n#'assignments.hw2.q1/val-data\n\n```\n:::\n\n\n`tc/split->seq` is a function that splits a dataset into two or more subsets. In this case, it's dividing the dataset into a test set and a training set. The `:holdout` option specifies that we want to split the dataset into two subsets, while the `:ratio` option determines the proportion of the dataset to include in the training set. \n  \n With this 90/10 split, we can further divide the training set into training and validation sets to tune our hyperparameters. The test set is already accessible in the data variable by calling `first`, which indicates the first element (map) of the sequence. The `:test` key in this map represents the 10% of the data set aside for testing, as specified in the `tc/split->seq` function call.\n\n***2) Write a function that uses the elbow method to select the value for K. You can set the range for K as (1, 15).***\n\n\n::: {.sourceClojure}\n```clojure\n(defn create-pipeline [params]\n  (morph/pipeline\n   (dsm/categorical->number [response])\n   (dsm/set-inference-target response)\n   {:metamorph/id :model}\n   (mm/model (merge {:model-type :sklearn.classification/k-neighbors-classifier}\n                    params))))\n```\n:::\n\n\nThis function creates a pipeline for the KNN model, converting categorical data to numbers, setting the inference target, and creating the model with given parameters.\n\n\n::: {.sourceClojure}\n```clojure\n(defn generate-hyperparams []\n  (grid/sobol-gridsearch\n   {:n-neighbors (grid/linear 1 15 15 :int32)\n    :weights     (grid/categorical [\"distance\"])\n    :metric      (grid/categorical [\"euclidean\" \"manhattan\" \"cosine\"])}))\n```\n:::\n\n\nThis function generates hyperparameters for the KNN model using Sobol sequence for efficient space exploration, including neighbors (1-15), weights, and distance metrics.\n\n\n::: {.sourceClojure}\n```clojure\n(grid/sobol-gridsearch\n {:n-neighbors (grid/linear 1 2 2 :int32)\n  :metric      (grid/categorical [\"euclidean\" \"manhattan\"])})\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n({:n-neighbors 2, :metric \"manhattan\"}\n {:n-neighbors 2, :metric \"euclidean\"}\n {:n-neighbors 1, :metric \"manhattan\"}\n {:n-neighbors 1, :metric \"euclidean\"})\n\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(defn evaluate-model [pipelines data-seq]\n  (mm/evaluate-pipelines\n   pipelines\n   data-seq\n   stats/cohens-kappa\n   :accuracy\n   {:other-metrices\n    [{:name :mathews-cor-coef :metric-fn stats/mcc}\n     {:name :accuracy :metric-fn loss/classification-accuracy}]\n    :return-best-pipeline-only        false\n    :return-best-crossvalidation-only true}))\n```\n:::\n\n\nThis function evaluates the model pipelines using various metrics like Cohen's kappa, Matthews correlation coefficient, and accuracy.\n\n\n::: {.sourceClojure}\n```clojure\n(defn process-results [evaluations]\n  (->> evaluations\n       flatten\n       (map #(hash-map\n              :summary (mm/thaw-model (get-in % [:fit-ctx :model]))\n              :fit-ctx (:fit-ctx %)\n              :timing-fit (:timing-fit %)\n              :metric ((comp :metric :test-transform) %)\n              :other-metrices ((comp :other-metrices :test-transform) %)\n              :params ((comp :options :model :fit-ctx) %)\n              :lookup-table (get-in % [:fit-ctx :model :target-categorical-maps :variety :lookup-table])\n              :pipe-fn (:pipe-fn %)))\n       (sort-by :metric)\n       reverse))\n```\n:::\n\n\nThis function processes the evaluation results, extracting relevant information and sorting the results by metric score in descending order.\n\n\n::: {.sourceClojure}\n```clojure\n(defn elbow-method [train-data val-data]\n  (let [pipelines (map create-pipeline (generate-hyperparams))\n        evaluations (evaluate-model pipelines [{:train train-data :test val-data}])]\n    (process-results evaluations)))\n```\n:::\n\n\nThis function implements the elbow method by creating pipelines with different hyperparameters, evaluating them, and processing the results to find the optimal K value.\n\n\n::: {.sourceClojure}\n```clojure\n(def elbow-results\n  (elbow-method train-data val-data))\n```\n:::\n\n\nThis line applies the elbow method to the training and validation data, storing the results as `elbow-results`.\n\n\n::: {.sourceClojure}\n```clojure\n(count elbow-results)\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n45\n\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(def results-dataset\n  (->> elbow-results\n       (map (fn [result]\n              (let [k (get-in result [:params :n-neighbors])\n                    dist-metric (get-in result [:params :metric])\n                    kappa (:metric result)\n                    other-metrics (:other-metrices result)\n                    mcc (-> (filter #(= (:name %) :mathews-cor-coef) other-metrics)\n                            first\n                            :metric)\n                    accuracy (-> (filter #(= (:name %) :accuracy) other-metrics)\n                                 first\n                                 :metric)]\n                {:k        k\n                 :metric   dist-metric\n                 :kappa    kappa\n                 :mcc      mcc\n                 :accuracy accuracy})))\n       (tc/dataset)))\n```\n:::\n\n\nThis code processes the elbow results, extracting key metrics (k, distance metric, kappa, MCC, accuracy) and creates a dataset for easier analysis and visualization.\n\n\n::: {.sourceClojure}\n```clojure\n(let [data (tc/select-rows results-dataset (comp #(= % \"euclidean\") :metric))]\n  (-> data\n      (haclo/layer-line {:=x :k :=y :kappa})\n      (haclo/layer-point {:=x         :k :=y :kappa\n                          :=mark-size 50})))\n```\n:::\n\n\n\n```{=html}\n<div><script>vegaEmbed(document.currentScript.parentElement, {\"encoding\":{\"x\":{\"field\":\"x\",\"type\":\"nominal\"},\"y\":{\"field\":\"y\",\"type\":\"nominal\"}},\"usermeta\":{\"embedOptions\":{\"renderer\":\"svg\"}},\"width\":400,\"background\":\"floralwhite\",\"layer\":[{\"mark\":{\"type\":\"line\",\"tooltip\":true},\"encoding\":{\"x\":{\"field\":\"k\",\"type\":\"quantitative\"},\"y\":{\"field\":\"kappa\",\"type\":\"quantitative\"}},\"data\":{\"values\":\"k,metric,kappa,mcc,accuracy\\n13,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n7,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n9,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n4,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n10,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n5,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n15,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n3,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n6,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n11,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n12,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n14,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n2,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n1,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n8,euclidean,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n\",\"format\":{\"type\":\"csv\"}}},{\"mark\":{\"type\":\"circle\",\"size\":50,\"tooltip\":true},\"encoding\":{\"x\":{\"field\":\"k\",\"type\":\"quantitative\"},\"y\":{\"field\":\"kappa\",\"type\":\"quantitative\"}},\"data\":{\"values\":\"k,metric,kappa,mcc,accuracy\\n13,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n7,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n9,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n4,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n10,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n5,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n15,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n3,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n6,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n11,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n12,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n14,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n2,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n1,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n8,euclidean,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n\",\"format\":{\"type\":\"csv\"}}}],\"height\":300,\"data\":{\"url\":\"assignments.hw2.q1_files\\/0.csv\",\"format\":{\"type\":\"csv\"}}});</script></div>\n```\n\n\nThis code creates a plot of the elbow method results for the Euclidean distance metric, showing how kappa changes with different K values.\n\n> <span style=\"color: black; font-size: 1.5em;\">**Looking at our elbow plot, we can see that the elbow dips down at $K=8$. Therefore, we want a K before 8. To me, 1 is too small and even numbers won't necessarily have a majority in a vote. I'd say good choices are 3, 5, or 7. I'll choose 5 because it's the middle value.**</span>\n\n***3) Explore different distance metrics and repeat part 2 with another distance metric. In the report, justify the value of K and the distance metric.***\n\n\n::: {.sourceClojure}\n```clojure\n(let [data (tc/select-rows results-dataset (comp #(= % \"manhattan\") :metric))]\n  (-> data\n      (haclo/layer-line {:=x :k :=y :mcc})\n      (haclo/layer-point {:=x         :k :=y :mcc\n                          :=mark-size 50})))\n```\n:::\n\n\n\n```{=html}\n<div><script>vegaEmbed(document.currentScript.parentElement, {\"encoding\":{\"x\":{\"field\":\"x\",\"type\":\"nominal\"},\"y\":{\"field\":\"y\",\"type\":\"nominal\"}},\"usermeta\":{\"embedOptions\":{\"renderer\":\"svg\"}},\"width\":400,\"background\":\"floralwhite\",\"layer\":[{\"mark\":{\"type\":\"line\",\"tooltip\":true},\"encoding\":{\"x\":{\"field\":\"k\",\"type\":\"quantitative\"},\"y\":{\"field\":\"mcc\",\"type\":\"quantitative\"}},\"data\":{\"values\":\"k,metric,kappa,mcc,accuracy\\n8,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n3,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n5,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n2,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n7,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n10,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n4,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n9,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n1,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n12,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n6,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n11,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n14,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n15,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n13,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n\",\"format\":{\"type\":\"csv\"}}},{\"mark\":{\"type\":\"circle\",\"size\":50,\"tooltip\":true},\"encoding\":{\"x\":{\"field\":\"k\",\"type\":\"quantitative\"},\"y\":{\"field\":\"mcc\",\"type\":\"quantitative\"}},\"data\":{\"values\":\"k,metric,kappa,mcc,accuracy\\n8,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n3,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n5,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n2,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n7,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n10,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n4,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n9,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n1,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n12,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n6,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n11,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n14,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n15,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n13,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n\",\"format\":{\"type\":\"csv\"}}}],\"height\":300,\"data\":{\"url\":\"assignments.hw2.q1_files\\/1.csv\",\"format\":{\"type\":\"csv\"}}});</script></div>\n```\n\n\n\n::: {.sourceClojure}\n```clojure\n(let [data (tc/select-rows results-dataset (comp #(= % \"cosine\") :metric))]\n  (-> data\n      (haclo/layer-line {:=x :k :=y :mcc})\n      (haclo/layer-point {:=x         :k :=y :mcc\n                          :=mark-size 50})))\n```\n:::\n\n\n\n```{=html}\n<div><script>vegaEmbed(document.currentScript.parentElement, {\"encoding\":{\"x\":{\"field\":\"x\",\"type\":\"nominal\"},\"y\":{\"field\":\"y\",\"type\":\"nominal\"}},\"usermeta\":{\"embedOptions\":{\"renderer\":\"svg\"}},\"width\":400,\"background\":\"floralwhite\",\"layer\":[{\"mark\":{\"type\":\"line\",\"tooltip\":true},\"encoding\":{\"x\":{\"field\":\"k\",\"type\":\"quantitative\"},\"y\":{\"field\":\"mcc\",\"type\":\"quantitative\"}},\"data\":{\"values\":\"k,metric,kappa,mcc,accuracy\\n10,cosine,1.0,1.0,1.0\\n12,cosine,1.0,1.0,1.0\\n14,cosine,1.0,1.0,1.0\\n6,cosine,1.0,1.0,1.0\\n15,cosine,1.0,1.0,1.0\\n5,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n4,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n9,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n8,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n1,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n3,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n11,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n2,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n7,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n13,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n\",\"format\":{\"type\":\"csv\"}}},{\"mark\":{\"type\":\"circle\",\"size\":50,\"tooltip\":true},\"encoding\":{\"x\":{\"field\":\"k\",\"type\":\"quantitative\"},\"y\":{\"field\":\"mcc\",\"type\":\"quantitative\"}},\"data\":{\"values\":\"k,metric,kappa,mcc,accuracy\\n10,cosine,1.0,1.0,1.0\\n12,cosine,1.0,1.0,1.0\\n14,cosine,1.0,1.0,1.0\\n6,cosine,1.0,1.0,1.0\\n15,cosine,1.0,1.0,1.0\\n5,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n4,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n9,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n8,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n1,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n3,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n11,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n2,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n7,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n13,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n\",\"format\":{\"type\":\"csv\"}}}],\"height\":300,\"data\":{\"url\":\"assignments.hw2.q1_files\\/2.csv\",\"format\":{\"type\":\"csv\"}}});</script></div>\n```\n\n\n\n**Justification for K value and distance metric:**\n\n*1. Euclidean distance (default):*\n     \n   - Optimal K: $[3, 5, 7]$\n   - This metric is suitable for continuous features and assumes all features contribute equally.\n   - It works well when the relationship between features is linear.\n\n*2. Manhattan distance:*\n     \n   - Optimal K: $[3, 5]$\n   - This metric is less sensitive to outliers compared to Euclidean distance.\n   - It's particularly useful when features are on different scales or when dealing with high-dimensional data.\n     \n*3. Cosine distance:*\n     \n   - Optimal K: $[6, 10, 12, 14, 15]$\n   - This metric is useful for high-dimensional data where feature scaling is important.\n   - It's particularly useful when the angle between data points is more important than their magnitude.\n\nThe choice between these metrics depends on the specific characteristics of the Iris dataset:\n\n- If the features are on similar scales and have a roughly linear relationship, Euclidean distance might be preferred.\n- If there are potential outliers or the features are on different scales, Manhattan distance could be more appropriate.\n- If the data is high-dimensional and feature scaling is important, cosine distance might be the best choice.\n\n> <span style=\"color: black; font-size: 1.5em;\">**The optimal K value balances between overfitting (low K) and underfitting (high K). The choice of distance metric depends on the specific characteristics of the dataset. Euclidean distance is a fine choice for this dataset for reasons explained above as well as being the easiest to understand. As such, I'd probably choose $K=5$ using the Euclidean distance metric.**</span>\n\n***4) Train the KNN model with the optimal K value and chosen distance metric on the combined train and validation sets.***\n\n\n::: {.sourceClojure}\n```clojure\n(def train-val-data-bootstrapped\n  (-> train-data\n      (tc/concat val-data)\n      (tc/split->seq :bootstrap {:seed 123 :repeats 25})))\n```\n:::\n\n\nThis code combines the training and validation data, then creates 25 bootstrap samples for robust model evaluation.\n\n\n::: {.sourceClojure}\n```clojure\n(def final-model\n  (let [pipelines (map create-pipeline [{:n-neighbors 5\n                                         :weights     \"distance\"\n                                         :metric      \"euclidean\"}])\n        evaluations (evaluate-model pipelines train-val-data-bootstrapped)]\n    (process-results evaluations)))\n```\n:::\n\n\nHere we define the final model using the chosen hyperparameters (5 neighbors, Euclidean distance) and evaluate it on the bootstrapped data.\n\n\n::: {.sourceClojure}\n```clojure\n(-> final-model first :lookup-table)\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n{\"Versicolor\" 0, \"Setosa\" 1, \"Virginica\" 2}\n\n```\n:::\n\n\nThis line retrieves the lookup table from the final model, which maps categorical labels to numerical values.\n\n***5) Evaluate the model on the test set and report the accuracy.***\n\n\n::: {.sourceClojure}\n```clojure\n(defn actual\n  [model]\n  (-> test-data :variety vec))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(defn preds\n  [model]\n  (let [lookup-table (-> model first :lookup-table)\n        reverse-lookup (zipmap (vals lookup-table) (keys lookup-table))]\n    (-> test-data\n        (morph/transform-pipe\n         (-> model first :pipe-fn)\n         (-> model first :fit-ctx))\n        :metamorph/data\n        :variety\n        (->> (map #(get reverse-lookup (long %)))\n             vec))))\n```\n:::\n\n\nThese functions extract the actual labels from the test data and generate predictions using the trained model, respectively.\n\n\n::: {.sourceClojure}\n```clojure\n(defn evaluate-predictions\n  \"Evaluates predictions against actual labels, returns confusion map and metrics.\"\n  [preds actual]\n  (let [conf-map (mlc/confusion-map->ds (mlc/confusion-map preds actual :none))\n        accuracy (loss/classification-accuracy preds actual)\n        kappa (stats/cohens-kappa preds actual)\n        mcc (stats/mcc preds actual)]\n    {:confusion-map conf-map\n     :accuracy      (format \"%.4f\" accuracy)\n     :cohens-kappa  (format \"%.4f\" kappa)\n     :mcc           (format \"%.4f\" mcc)}))\n```\n:::\n\n\n`evaluate-predictions` calculates various performance metrics including accuracy, Cohen's kappa, and Matthews correlation coefficient, along with a confusion matrix. At last, we generate predictions on the test set, compare them with the actual labels, and compute the evaluation metrics to assess the model's performance.\n\n\n::: {.sourceClojure}\n```clojure\n(let [preds (preds final-model)\n      actual (actual final-model)]\n  (evaluate-predictions preds actual))\n```\n:::\n\n\n\n```{=html}\n<div><p>{</p><div class=\"clay-map\" style=\"margin-left:10%;width:110%;\"><table><tr><td valign=\"top\"><div><pre><code class=\"sourceCode language-clojure printed-clojure\">:confusion-map\n</code></pre></div></td><td><div style=\"margin-left:10px;\"><div class=\"clay-dataset\"><p>_unnamed [3 4]:</p><table class=\"table\"><thead><tr><th>:column-name</th><th>Setosa</th><th>Versicolor</th><th>Virginica</th></tr></thead><tbody><tr><td>Setosa</td><td>5</td><td>0</td><td>0</td></tr><tr><td>Versicolor</td><td>0</td><td>5</td><td>0</td></tr><tr><td>Virginica</td><td>0</td><td>1</td><td>4</td></tr></tbody></table></div></div></td></tr></table><div><pre><code class=\"sourceCode language-clojure printed-clojure\">:accuracy &quot;0.9333&quot;</code></pre></div><div><pre><code class=\"sourceCode language-clojure printed-clojure\">:cohens-kappa &quot;0.9000&quot;</code></pre></div><div><pre><code class=\"sourceCode language-clojure printed-clojure\">:mcc &quot;0.9061&quot;</code></pre></div></div><p>}</p></div>\n```\n\n\n\n::: {.sourceClojure}\n```clojure\n(answer (str \"Accuracy on the Iris test set: \"\n             (get-in (let [preds (preds final-model)\n                           actual (actual final-model)]\n                       (evaluate-predictions preds actual))\n                     [:accuracy])))\n```\n:::\n\n\n> <span style=\"color: black; font-size: 1.5em;\">**Accuracy on the Iris test set: 0.9333**</span>\n\n***6) Provide a brief analysis of the results in your report.***\n\n### Analysis of Results:\n\n#### 1. Data Split: \n  We used a 70/20/10 split for train/validation/test, which is a common practice. This split provides enough data for training while reserving sufficient data for validation and testing. However, the Iris dataset is small, where the 10% holdout is just 15 samples.\n\n#### 2. Elbow Method: \n  This approach effectively determined the optimal K value, balancing between model complexity and performance, between underfitting and overfitting.\n\n#### 3. Distance Metrics:\n  Comparison of Euclidean and Manhattan distances revealed metric-dependent optimal K values, underscoring the importance of metric selection in KNN.\n\n#### 4. Final Model:\n  We selected Euclidean distance with K = 5, based on the elbow method results. This choice aims to balance model simplicity with performance.\n\n#### 5. Model Performance:\n  The final accuracy of $0.9333$ on the test set demonstrates strong generalization to unseen data, validating our K and distance metric choices.\n\n#### 6. Limitations and Future Work:\n  \n  - Explore additional distance metrics and feature scaling techniques for potential performance improvements.\n  - Implement k-fold cross-validation for more robust performance estimation.\n  - Conduct feature importance analysis to identify key iris characteristics for classification.\n  - Consider testing the model on a larger, more diverse dataset to assess its broader applicability.\n\n\n```{=html}\n<div style=\"background-color:grey;height:2px;width:100%;\"></div>\n```\n\n\n\n```{=html}\n<div></div>\n```\n","srcMarkdownNoYaml":"\n<style></style><style>.printedClojure .sourceCode {\n  background-color: transparent;\n  border-style: none;\n}\n</style><style>.clay-limit-image-width .clay-image {max-width: 100%}\n.clay-side-by-side .sourceCode {margin: 0}\n.clay-side-by-side {margin: 1em 0}\n</style>\n<script src=\"assignments.hw2.q1_files/md-default3.js\" type=\"text/javascript\"></script><script src=\"assignments.hw2.q1_files/md-default4.js\" type=\"text/javascript\"></script><script src=\"assignments.hw2.q1_files/vega5.js\" type=\"text/javascript\"></script><script src=\"assignments.hw2.q1_files/vega6.js\" type=\"text/javascript\"></script><script src=\"assignments.hw2.q1_files/vega7.js\" type=\"text/javascript\"></script>\n\n::: {.sourceClojure}\n```clojure\n(ns assignments.hw2.q1\n  (:require\n   [my-py-clj.config :refer :all]\n   [assignments.hw2.utils :refer :all]\n   [fastmath.stats :as stats]\n  ;;  [libpython-clj2.python :refer [py.-]]\n  ;;  [scicloj.sklearn-clj.metamorph :as sklearn-mm]\n   [scicloj.hanamicloth.v1.api :as haclo]\n   [scicloj.metamorph.core :as morph]\n   [scicloj.metamorph.ml :as mm]\n   [scicloj.metamorph.ml.classification :as mlc]\n   [scicloj.metamorph.ml.gridsearch :as grid]\n   [scicloj.metamorph.ml.loss :as loss]\n   [scicloj.sklearn-clj :as sklearn-clj]\n   [scicloj.sklearn-clj.ml]                                ;; registers all models\n   [tablecloth.api :as tc]\n   [tech.v3.dataset.metamorph :as dsm]\n   [tech.v3.dataset.modelling :as ds-mod]))\n```\n:::\n\n\n## Question 1\n---\n\n#### *Q1: Classification with Nearest Neighbor (30 Points)*\n\nFor this question, you will need to perform KNN on the famous Iris data set. You are required to use Scki-learn to completion this question. The data is stored in a csv file and it can be downloaded from Canvas. For the description of the data set, you can visit: [Wikipedia iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set).\n\n***1) Load the data and split it into train, valid, and test (70/20/10).***\n\n\n::: {.sourceClojure}\n```clojure\n(defonce iris (-> \"data/A1Q1_Data.csv\"\n                  (tc/dataset {:key-fn (fn [colname]\n                                         (-> colname    ;kabab-case keyword\n                                             (clojure.string/replace #\"\\.|\\s\" \"-\")\n                                             clojure.string/lower-case\n                                             keyword))})\n                  (ds-mod/set-inference-target :variety)))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(def response :variety)\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(def regressors\n  (tc/column-names iris (complement #{response})))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(let [data (-> iris\n               (tc/split->seq :holdout {:seed 123 :ratio 0.9}))\n      test-data (-> data first :test)\n      train-val-data (-> data first :train\n                         (tc/split->seq :holdout {:seed 123}))\n      train-data (-> train-val-data first :train)\n      val-data (-> train-val-data first :test)]\n  (def test-data test-data)\n  (def train-data train-data)\n  (def val-data val-data))\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n#'assignments.hw2.q1/val-data\n\n```\n:::\n\n\n`tc/split->seq` is a function that splits a dataset into two or more subsets. In this case, it's dividing the dataset into a test set and a training set. The `:holdout` option specifies that we want to split the dataset into two subsets, while the `:ratio` option determines the proportion of the dataset to include in the training set. \n  \n With this 90/10 split, we can further divide the training set into training and validation sets to tune our hyperparameters. The test set is already accessible in the data variable by calling `first`, which indicates the first element (map) of the sequence. The `:test` key in this map represents the 10% of the data set aside for testing, as specified in the `tc/split->seq` function call.\n\n***2) Write a function that uses the elbow method to select the value for K. You can set the range for K as (1, 15).***\n\n\n::: {.sourceClojure}\n```clojure\n(defn create-pipeline [params]\n  (morph/pipeline\n   (dsm/categorical->number [response])\n   (dsm/set-inference-target response)\n   {:metamorph/id :model}\n   (mm/model (merge {:model-type :sklearn.classification/k-neighbors-classifier}\n                    params))))\n```\n:::\n\n\nThis function creates a pipeline for the KNN model, converting categorical data to numbers, setting the inference target, and creating the model with given parameters.\n\n\n::: {.sourceClojure}\n```clojure\n(defn generate-hyperparams []\n  (grid/sobol-gridsearch\n   {:n-neighbors (grid/linear 1 15 15 :int32)\n    :weights     (grid/categorical [\"distance\"])\n    :metric      (grid/categorical [\"euclidean\" \"manhattan\" \"cosine\"])}))\n```\n:::\n\n\nThis function generates hyperparameters for the KNN model using Sobol sequence for efficient space exploration, including neighbors (1-15), weights, and distance metrics.\n\n\n::: {.sourceClojure}\n```clojure\n(grid/sobol-gridsearch\n {:n-neighbors (grid/linear 1 2 2 :int32)\n  :metric      (grid/categorical [\"euclidean\" \"manhattan\"])})\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n({:n-neighbors 2, :metric \"manhattan\"}\n {:n-neighbors 2, :metric \"euclidean\"}\n {:n-neighbors 1, :metric \"manhattan\"}\n {:n-neighbors 1, :metric \"euclidean\"})\n\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(defn evaluate-model [pipelines data-seq]\n  (mm/evaluate-pipelines\n   pipelines\n   data-seq\n   stats/cohens-kappa\n   :accuracy\n   {:other-metrices\n    [{:name :mathews-cor-coef :metric-fn stats/mcc}\n     {:name :accuracy :metric-fn loss/classification-accuracy}]\n    :return-best-pipeline-only        false\n    :return-best-crossvalidation-only true}))\n```\n:::\n\n\nThis function evaluates the model pipelines using various metrics like Cohen's kappa, Matthews correlation coefficient, and accuracy.\n\n\n::: {.sourceClojure}\n```clojure\n(defn process-results [evaluations]\n  (->> evaluations\n       flatten\n       (map #(hash-map\n              :summary (mm/thaw-model (get-in % [:fit-ctx :model]))\n              :fit-ctx (:fit-ctx %)\n              :timing-fit (:timing-fit %)\n              :metric ((comp :metric :test-transform) %)\n              :other-metrices ((comp :other-metrices :test-transform) %)\n              :params ((comp :options :model :fit-ctx) %)\n              :lookup-table (get-in % [:fit-ctx :model :target-categorical-maps :variety :lookup-table])\n              :pipe-fn (:pipe-fn %)))\n       (sort-by :metric)\n       reverse))\n```\n:::\n\n\nThis function processes the evaluation results, extracting relevant information and sorting the results by metric score in descending order.\n\n\n::: {.sourceClojure}\n```clojure\n(defn elbow-method [train-data val-data]\n  (let [pipelines (map create-pipeline (generate-hyperparams))\n        evaluations (evaluate-model pipelines [{:train train-data :test val-data}])]\n    (process-results evaluations)))\n```\n:::\n\n\nThis function implements the elbow method by creating pipelines with different hyperparameters, evaluating them, and processing the results to find the optimal K value.\n\n\n::: {.sourceClojure}\n```clojure\n(def elbow-results\n  (elbow-method train-data val-data))\n```\n:::\n\n\nThis line applies the elbow method to the training and validation data, storing the results as `elbow-results`.\n\n\n::: {.sourceClojure}\n```clojure\n(count elbow-results)\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n45\n\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(def results-dataset\n  (->> elbow-results\n       (map (fn [result]\n              (let [k (get-in result [:params :n-neighbors])\n                    dist-metric (get-in result [:params :metric])\n                    kappa (:metric result)\n                    other-metrics (:other-metrices result)\n                    mcc (-> (filter #(= (:name %) :mathews-cor-coef) other-metrics)\n                            first\n                            :metric)\n                    accuracy (-> (filter #(= (:name %) :accuracy) other-metrics)\n                                 first\n                                 :metric)]\n                {:k        k\n                 :metric   dist-metric\n                 :kappa    kappa\n                 :mcc      mcc\n                 :accuracy accuracy})))\n       (tc/dataset)))\n```\n:::\n\n\nThis code processes the elbow results, extracting key metrics (k, distance metric, kappa, MCC, accuracy) and creates a dataset for easier analysis and visualization.\n\n\n::: {.sourceClojure}\n```clojure\n(let [data (tc/select-rows results-dataset (comp #(= % \"euclidean\") :metric))]\n  (-> data\n      (haclo/layer-line {:=x :k :=y :kappa})\n      (haclo/layer-point {:=x         :k :=y :kappa\n                          :=mark-size 50})))\n```\n:::\n\n\n\n```{=html}\n<div><script>vegaEmbed(document.currentScript.parentElement, {\"encoding\":{\"x\":{\"field\":\"x\",\"type\":\"nominal\"},\"y\":{\"field\":\"y\",\"type\":\"nominal\"}},\"usermeta\":{\"embedOptions\":{\"renderer\":\"svg\"}},\"width\":400,\"background\":\"floralwhite\",\"layer\":[{\"mark\":{\"type\":\"line\",\"tooltip\":true},\"encoding\":{\"x\":{\"field\":\"k\",\"type\":\"quantitative\"},\"y\":{\"field\":\"kappa\",\"type\":\"quantitative\"}},\"data\":{\"values\":\"k,metric,kappa,mcc,accuracy\\n13,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n7,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n9,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n4,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n10,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n5,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n15,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n3,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n6,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n11,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n12,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n14,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n2,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n1,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n8,euclidean,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n\",\"format\":{\"type\":\"csv\"}}},{\"mark\":{\"type\":\"circle\",\"size\":50,\"tooltip\":true},\"encoding\":{\"x\":{\"field\":\"k\",\"type\":\"quantitative\"},\"y\":{\"field\":\"kappa\",\"type\":\"quantitative\"}},\"data\":{\"values\":\"k,metric,kappa,mcc,accuracy\\n13,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n7,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n9,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n4,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n10,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n5,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n15,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n3,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n6,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n11,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n12,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n14,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n2,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n1,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n8,euclidean,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n\",\"format\":{\"type\":\"csv\"}}}],\"height\":300,\"data\":{\"url\":\"assignments.hw2.q1_files\\/0.csv\",\"format\":{\"type\":\"csv\"}}});</script></div>\n```\n\n\nThis code creates a plot of the elbow method results for the Euclidean distance metric, showing how kappa changes with different K values.\n\n> <span style=\"color: black; font-size: 1.5em;\">**Looking at our elbow plot, we can see that the elbow dips down at $K=8$. Therefore, we want a K before 8. To me, 1 is too small and even numbers won't necessarily have a majority in a vote. I'd say good choices are 3, 5, or 7. I'll choose 5 because it's the middle value.**</span>\n\n***3) Explore different distance metrics and repeat part 2 with another distance metric. In the report, justify the value of K and the distance metric.***\n\n\n::: {.sourceClojure}\n```clojure\n(let [data (tc/select-rows results-dataset (comp #(= % \"manhattan\") :metric))]\n  (-> data\n      (haclo/layer-line {:=x :k :=y :mcc})\n      (haclo/layer-point {:=x         :k :=y :mcc\n                          :=mark-size 50})))\n```\n:::\n\n\n\n```{=html}\n<div><script>vegaEmbed(document.currentScript.parentElement, {\"encoding\":{\"x\":{\"field\":\"x\",\"type\":\"nominal\"},\"y\":{\"field\":\"y\",\"type\":\"nominal\"}},\"usermeta\":{\"embedOptions\":{\"renderer\":\"svg\"}},\"width\":400,\"background\":\"floralwhite\",\"layer\":[{\"mark\":{\"type\":\"line\",\"tooltip\":true},\"encoding\":{\"x\":{\"field\":\"k\",\"type\":\"quantitative\"},\"y\":{\"field\":\"mcc\",\"type\":\"quantitative\"}},\"data\":{\"values\":\"k,metric,kappa,mcc,accuracy\\n8,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n3,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n5,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n2,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n7,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n10,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n4,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n9,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n1,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n12,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n6,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n11,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n14,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n15,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n13,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n\",\"format\":{\"type\":\"csv\"}}},{\"mark\":{\"type\":\"circle\",\"size\":50,\"tooltip\":true},\"encoding\":{\"x\":{\"field\":\"k\",\"type\":\"quantitative\"},\"y\":{\"field\":\"mcc\",\"type\":\"quantitative\"}},\"data\":{\"values\":\"k,metric,kappa,mcc,accuracy\\n8,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n3,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n5,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n2,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n7,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n10,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n4,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n9,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n1,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n12,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n6,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n11,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n14,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n15,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n13,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\\n\",\"format\":{\"type\":\"csv\"}}}],\"height\":300,\"data\":{\"url\":\"assignments.hw2.q1_files\\/1.csv\",\"format\":{\"type\":\"csv\"}}});</script></div>\n```\n\n\n\n::: {.sourceClojure}\n```clojure\n(let [data (tc/select-rows results-dataset (comp #(= % \"cosine\") :metric))]\n  (-> data\n      (haclo/layer-line {:=x :k :=y :mcc})\n      (haclo/layer-point {:=x         :k :=y :mcc\n                          :=mark-size 50})))\n```\n:::\n\n\n\n```{=html}\n<div><script>vegaEmbed(document.currentScript.parentElement, {\"encoding\":{\"x\":{\"field\":\"x\",\"type\":\"nominal\"},\"y\":{\"field\":\"y\",\"type\":\"nominal\"}},\"usermeta\":{\"embedOptions\":{\"renderer\":\"svg\"}},\"width\":400,\"background\":\"floralwhite\",\"layer\":[{\"mark\":{\"type\":\"line\",\"tooltip\":true},\"encoding\":{\"x\":{\"field\":\"k\",\"type\":\"quantitative\"},\"y\":{\"field\":\"mcc\",\"type\":\"quantitative\"}},\"data\":{\"values\":\"k,metric,kappa,mcc,accuracy\\n10,cosine,1.0,1.0,1.0\\n12,cosine,1.0,1.0,1.0\\n14,cosine,1.0,1.0,1.0\\n6,cosine,1.0,1.0,1.0\\n15,cosine,1.0,1.0,1.0\\n5,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n4,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n9,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n8,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n1,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n3,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n11,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n2,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n7,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n13,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n\",\"format\":{\"type\":\"csv\"}}},{\"mark\":{\"type\":\"circle\",\"size\":50,\"tooltip\":true},\"encoding\":{\"x\":{\"field\":\"k\",\"type\":\"quantitative\"},\"y\":{\"field\":\"mcc\",\"type\":\"quantitative\"}},\"data\":{\"values\":\"k,metric,kappa,mcc,accuracy\\n10,cosine,1.0,1.0,1.0\\n12,cosine,1.0,1.0,1.0\\n14,cosine,1.0,1.0,1.0\\n6,cosine,1.0,1.0,1.0\\n15,cosine,1.0,1.0,1.0\\n5,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n4,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n9,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n8,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n1,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n3,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n11,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n2,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n7,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n13,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\\n\",\"format\":{\"type\":\"csv\"}}}],\"height\":300,\"data\":{\"url\":\"assignments.hw2.q1_files\\/2.csv\",\"format\":{\"type\":\"csv\"}}});</script></div>\n```\n\n\n\n**Justification for K value and distance metric:**\n\n*1. Euclidean distance (default):*\n     \n   - Optimal K: $[3, 5, 7]$\n   - This metric is suitable for continuous features and assumes all features contribute equally.\n   - It works well when the relationship between features is linear.\n\n*2. Manhattan distance:*\n     \n   - Optimal K: $[3, 5]$\n   - This metric is less sensitive to outliers compared to Euclidean distance.\n   - It's particularly useful when features are on different scales or when dealing with high-dimensional data.\n     \n*3. Cosine distance:*\n     \n   - Optimal K: $[6, 10, 12, 14, 15]$\n   - This metric is useful for high-dimensional data where feature scaling is important.\n   - It's particularly useful when the angle between data points is more important than their magnitude.\n\nThe choice between these metrics depends on the specific characteristics of the Iris dataset:\n\n- If the features are on similar scales and have a roughly linear relationship, Euclidean distance might be preferred.\n- If there are potential outliers or the features are on different scales, Manhattan distance could be more appropriate.\n- If the data is high-dimensional and feature scaling is important, cosine distance might be the best choice.\n\n> <span style=\"color: black; font-size: 1.5em;\">**The optimal K value balances between overfitting (low K) and underfitting (high K). The choice of distance metric depends on the specific characteristics of the dataset. Euclidean distance is a fine choice for this dataset for reasons explained above as well as being the easiest to understand. As such, I'd probably choose $K=5$ using the Euclidean distance metric.**</span>\n\n***4) Train the KNN model with the optimal K value and chosen distance metric on the combined train and validation sets.***\n\n\n::: {.sourceClojure}\n```clojure\n(def train-val-data-bootstrapped\n  (-> train-data\n      (tc/concat val-data)\n      (tc/split->seq :bootstrap {:seed 123 :repeats 25})))\n```\n:::\n\n\nThis code combines the training and validation data, then creates 25 bootstrap samples for robust model evaluation.\n\n\n::: {.sourceClojure}\n```clojure\n(def final-model\n  (let [pipelines (map create-pipeline [{:n-neighbors 5\n                                         :weights     \"distance\"\n                                         :metric      \"euclidean\"}])\n        evaluations (evaluate-model pipelines train-val-data-bootstrapped)]\n    (process-results evaluations)))\n```\n:::\n\n\nHere we define the final model using the chosen hyperparameters (5 neighbors, Euclidean distance) and evaluate it on the bootstrapped data.\n\n\n::: {.sourceClojure}\n```clojure\n(-> final-model first :lookup-table)\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n{\"Versicolor\" 0, \"Setosa\" 1, \"Virginica\" 2}\n\n```\n:::\n\n\nThis line retrieves the lookup table from the final model, which maps categorical labels to numerical values.\n\n***5) Evaluate the model on the test set and report the accuracy.***\n\n\n::: {.sourceClojure}\n```clojure\n(defn actual\n  [model]\n  (-> test-data :variety vec))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(defn preds\n  [model]\n  (let [lookup-table (-> model first :lookup-table)\n        reverse-lookup (zipmap (vals lookup-table) (keys lookup-table))]\n    (-> test-data\n        (morph/transform-pipe\n         (-> model first :pipe-fn)\n         (-> model first :fit-ctx))\n        :metamorph/data\n        :variety\n        (->> (map #(get reverse-lookup (long %)))\n             vec))))\n```\n:::\n\n\nThese functions extract the actual labels from the test data and generate predictions using the trained model, respectively.\n\n\n::: {.sourceClojure}\n```clojure\n(defn evaluate-predictions\n  \"Evaluates predictions against actual labels, returns confusion map and metrics.\"\n  [preds actual]\n  (let [conf-map (mlc/confusion-map->ds (mlc/confusion-map preds actual :none))\n        accuracy (loss/classification-accuracy preds actual)\n        kappa (stats/cohens-kappa preds actual)\n        mcc (stats/mcc preds actual)]\n    {:confusion-map conf-map\n     :accuracy      (format \"%.4f\" accuracy)\n     :cohens-kappa  (format \"%.4f\" kappa)\n     :mcc           (format \"%.4f\" mcc)}))\n```\n:::\n\n\n`evaluate-predictions` calculates various performance metrics including accuracy, Cohen's kappa, and Matthews correlation coefficient, along with a confusion matrix. At last, we generate predictions on the test set, compare them with the actual labels, and compute the evaluation metrics to assess the model's performance.\n\n\n::: {.sourceClojure}\n```clojure\n(let [preds (preds final-model)\n      actual (actual final-model)]\n  (evaluate-predictions preds actual))\n```\n:::\n\n\n\n```{=html}\n<div><p>{</p><div class=\"clay-map\" style=\"margin-left:10%;width:110%;\"><table><tr><td valign=\"top\"><div><pre><code class=\"sourceCode language-clojure printed-clojure\">:confusion-map\n</code></pre></div></td><td><div style=\"margin-left:10px;\"><div class=\"clay-dataset\"><p>_unnamed [3 4]:</p><table class=\"table\"><thead><tr><th>:column-name</th><th>Setosa</th><th>Versicolor</th><th>Virginica</th></tr></thead><tbody><tr><td>Setosa</td><td>5</td><td>0</td><td>0</td></tr><tr><td>Versicolor</td><td>0</td><td>5</td><td>0</td></tr><tr><td>Virginica</td><td>0</td><td>1</td><td>4</td></tr></tbody></table></div></div></td></tr></table><div><pre><code class=\"sourceCode language-clojure printed-clojure\">:accuracy &quot;0.9333&quot;</code></pre></div><div><pre><code class=\"sourceCode language-clojure printed-clojure\">:cohens-kappa &quot;0.9000&quot;</code></pre></div><div><pre><code class=\"sourceCode language-clojure printed-clojure\">:mcc &quot;0.9061&quot;</code></pre></div></div><p>}</p></div>\n```\n\n\n\n::: {.sourceClojure}\n```clojure\n(answer (str \"Accuracy on the Iris test set: \"\n             (get-in (let [preds (preds final-model)\n                           actual (actual final-model)]\n                       (evaluate-predictions preds actual))\n                     [:accuracy])))\n```\n:::\n\n\n> <span style=\"color: black; font-size: 1.5em;\">**Accuracy on the Iris test set: 0.9333**</span>\n\n***6) Provide a brief analysis of the results in your report.***\n\n### Analysis of Results:\n\n#### 1. Data Split: \n  We used a 70/20/10 split for train/validation/test, which is a common practice. This split provides enough data for training while reserving sufficient data for validation and testing. However, the Iris dataset is small, where the 10% holdout is just 15 samples.\n\n#### 2. Elbow Method: \n  This approach effectively determined the optimal K value, balancing between model complexity and performance, between underfitting and overfitting.\n\n#### 3. Distance Metrics:\n  Comparison of Euclidean and Manhattan distances revealed metric-dependent optimal K values, underscoring the importance of metric selection in KNN.\n\n#### 4. Final Model:\n  We selected Euclidean distance with K = 5, based on the elbow method results. This choice aims to balance model simplicity with performance.\n\n#### 5. Model Performance:\n  The final accuracy of $0.9333$ on the test set demonstrates strong generalization to unseen data, validating our K and distance metric choices.\n\n#### 6. Limitations and Future Work:\n  \n  - Explore additional distance metrics and feature scaling techniques for potential performance improvements.\n  - Implement k-fold cross-validation for more robust performance estimation.\n  - Conduct feature importance analysis to identify key iris characteristics for classification.\n  - Consider testing the model on a larger, more diverse dataset to assess its broader applicability.\n\n\n```{=html}\n<div style=\"background-color:grey;height:2px;width:100%;\"></div>\n```\n\n\n\n```{=html}\n<div></div>\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":3,"number-sections":false,"include-in-header":{"text":"<link rel = \"icon\" href = \"data:,\" />"},"output-file":"assignments.hw2.q1.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","theme":"cosmo","fontsize":"0.9em","code-block-background":true,"toc-title-numbers":false,"number-depth":0},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html","revealjs"]}