
---
format:
  html: {toc: true, toc-depth: 3, theme: cosmo, number-sections: false, output-file: assignments.hw2.q1.html}
fontsize: 0.9em
code-block-background: true
include-in-header: {text: '<link rel = "icon" href = "data:," />'}
toc-title-numbers: false
number-depth: 0

---
<style></style><style>.printedClojure .sourceCode {
  background-color: transparent;
  border-style: none;
}
</style><style>.clay-limit-image-width .clay-image {max-width: 100%}
.clay-side-by-side .sourceCode {margin: 0}
.clay-side-by-side {margin: 1em 0}
</style>
<script src="assignments.hw2.q1_files/md-default3.js" type="text/javascript"></script><script src="assignments.hw2.q1_files/md-default4.js" type="text/javascript"></script><script src="assignments.hw2.q1_files/vega5.js" type="text/javascript"></script><script src="assignments.hw2.q1_files/vega6.js" type="text/javascript"></script><script src="assignments.hw2.q1_files/vega7.js" type="text/javascript"></script>

::: {.sourceClojure}
```clojure
(ns assignments.hw2.q1
  (:require
   [my-py-clj.config :refer :all]
   [assignments.hw2.utils :refer :all]
   [fastmath.stats :as stats]
  ;;  [libpython-clj2.python :refer [py.-]]
  ;;  [scicloj.sklearn-clj.metamorph :as sklearn-mm]
   [scicloj.hanamicloth.v1.api :as haclo]
   [scicloj.metamorph.core :as morph]
   [scicloj.metamorph.ml :as mm]
   [scicloj.metamorph.ml.classification :as mlc]
   [scicloj.metamorph.ml.gridsearch :as grid]
   [scicloj.metamorph.ml.loss :as loss]
   [scicloj.sklearn-clj :as sklearn-clj]
   [scicloj.sklearn-clj.ml]                                ;; registers all models
   [tablecloth.api :as tc]
   [tech.v3.dataset.metamorph :as dsm]
   [tech.v3.dataset.modelling :as ds-mod]))
```
:::


## Question 1
---

#### *Q1: Classification with Nearest Neighbor (30 Points)*

For this question, you will need to perform KNN on the famous Iris data set. You are required to use Scki-learn to completion this question. The data is stored in a csv file and it can be downloaded from Canvas. For the description of the data set, you can visit: [Wikipedia iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set).

***1) Load the data and split it into train, valid, and test (70/20/10).***


::: {.sourceClojure}
```clojure
(defonce iris (-> "data/A1Q1_Data.csv"
                  (tc/dataset {:key-fn (fn [colname]
                                         (-> colname    ;kabab-case keyword
                                             (clojure.string/replace #"\.|\s" "-")
                                             clojure.string/lower-case
                                             keyword))})
                  (ds-mod/set-inference-target :variety)))
```
:::



::: {.sourceClojure}
```clojure
(def response :variety)
```
:::



::: {.sourceClojure}
```clojure
(def regressors
  (tc/column-names iris (complement #{response})))
```
:::



::: {.sourceClojure}
```clojure
(let [data (-> iris
               (tc/split->seq :holdout {:seed 123 :ratio 0.9}))
      test-data (-> data first :test)
      train-val-data (-> data first :train
                         (tc/split->seq :holdout {:seed 123}))
      train-data (-> train-val-data first :train)
      val-data (-> train-val-data first :test)]
  (def test-data test-data)
  (def train-data train-data)
  (def val-data val-data))
```
:::



::: {.printedClojure}
```clojure
#'assignments.hw2.q1/val-data

```
:::


`tc/split->seq` is a function that splits a dataset into two or more subsets. In this case, it's dividing the dataset into a test set and a training set. The `:holdout` option specifies that we want to split the dataset into two subsets, while the `:ratio` option determines the proportion of the dataset to include in the training set. 
  
 With this 90/10 split, we can further divide the training set into training and validation sets to tune our hyperparameters. The test set is already accessible in the data variable by calling `first`, which indicates the first element (map) of the sequence. The `:test` key in this map represents the 10% of the data set aside for testing, as specified in the `tc/split->seq` function call.

***2) Write a function that uses the elbow method to select the value for K. You can set the range for K as (1, 15).***


::: {.sourceClojure}
```clojure
(defn create-pipeline [params]
  (morph/pipeline
   (dsm/categorical->number [response])
   (dsm/set-inference-target response)
   {:metamorph/id :model}
   (mm/model (merge {:model-type :sklearn.classification/k-neighbors-classifier}
                    params))))
```
:::


This function creates a pipeline for the KNN model, converting categorical data to numbers, setting the inference target, and creating the model with given parameters.


::: {.sourceClojure}
```clojure
(defn generate-hyperparams []
  (grid/sobol-gridsearch
   {:n-neighbors (grid/linear 1 15 15 :int32)
    :weights     (grid/categorical ["distance"])
    :metric      (grid/categorical ["euclidean" "manhattan" "cosine"])}))
```
:::


This function generates hyperparameters for the KNN model using Sobol sequence for efficient space exploration, including neighbors (1-15), weights, and distance metrics.


::: {.sourceClojure}
```clojure
(grid/sobol-gridsearch
 {:n-neighbors (grid/linear 1 2 2 :int32)
  :metric      (grid/categorical ["euclidean" "manhattan"])})
```
:::



::: {.printedClojure}
```clojure
({:n-neighbors 2, :metric "manhattan"}
 {:n-neighbors 2, :metric "euclidean"}
 {:n-neighbors 1, :metric "manhattan"}
 {:n-neighbors 1, :metric "euclidean"})

```
:::



::: {.sourceClojure}
```clojure
(defn evaluate-model [pipelines data-seq]
  (mm/evaluate-pipelines
   pipelines
   data-seq
   stats/cohens-kappa
   :accuracy
   {:other-metrices
    [{:name :mathews-cor-coef :metric-fn stats/mcc}
     {:name :accuracy :metric-fn loss/classification-accuracy}]
    :return-best-pipeline-only        false
    :return-best-crossvalidation-only true}))
```
:::


This function evaluates the model pipelines using various metrics like Cohen's kappa, Matthews correlation coefficient, and accuracy.


::: {.sourceClojure}
```clojure
(defn process-results [evaluations]
  (->> evaluations
       flatten
       (map #(hash-map
              :summary (mm/thaw-model (get-in % [:fit-ctx :model]))
              :fit-ctx (:fit-ctx %)
              :timing-fit (:timing-fit %)
              :metric ((comp :metric :test-transform) %)
              :other-metrices ((comp :other-metrices :test-transform) %)
              :params ((comp :options :model :fit-ctx) %)
              :lookup-table (get-in % [:fit-ctx :model :target-categorical-maps :variety :lookup-table])
              :pipe-fn (:pipe-fn %)))
       (sort-by :metric)
       reverse))
```
:::


This function processes the evaluation results, extracting relevant information and sorting the results by metric score in descending order.


::: {.sourceClojure}
```clojure
(defn elbow-method [train-data val-data]
  (let [pipelines (map create-pipeline (generate-hyperparams))
        evaluations (evaluate-model pipelines [{:train train-data :test val-data}])]
    (process-results evaluations)))
```
:::


This function implements the elbow method by creating pipelines with different hyperparameters, evaluating them, and processing the results to find the optimal K value.


::: {.sourceClojure}
```clojure
(def elbow-results
  (elbow-method train-data val-data))
```
:::


This line applies the elbow method to the training and validation data, storing the results as `elbow-results`.


::: {.sourceClojure}
```clojure
(count elbow-results)
```
:::



::: {.printedClojure}
```clojure
45

```
:::



::: {.sourceClojure}
```clojure
(def results-dataset
  (->> elbow-results
       (map (fn [result]
              (let [k (get-in result [:params :n-neighbors])
                    dist-metric (get-in result [:params :metric])
                    kappa (:metric result)
                    other-metrics (:other-metrices result)
                    mcc (-> (filter #(= (:name %) :mathews-cor-coef) other-metrics)
                            first
                            :metric)
                    accuracy (-> (filter #(= (:name %) :accuracy) other-metrics)
                                 first
                                 :metric)]
                {:k        k
                 :metric   dist-metric
                 :kappa    kappa
                 :mcc      mcc
                 :accuracy accuracy})))
       (tc/dataset)))
```
:::


This code processes the elbow results, extracting key metrics (k, distance metric, kappa, MCC, accuracy) and creates a dataset for easier analysis and visualization.


::: {.sourceClojure}
```clojure
(let [data (tc/select-rows results-dataset (comp #(= % "euclidean") :metric))]
  (-> data
      (haclo/layer-line {:=x :k :=y :kappa})
      (haclo/layer-point {:=x         :k :=y :kappa
                          :=mark-size 50})))
```
:::



```{=html}
<div><script>vegaEmbed(document.currentScript.parentElement, {"encoding":{"x":{"field":"x","type":"nominal"},"y":{"field":"y","type":"nominal"}},"usermeta":{"embedOptions":{"renderer":"svg"}},"width":400,"background":"floralwhite","layer":[{"mark":{"type":"line","tooltip":true},"encoding":{"x":{"field":"k","type":"quantitative"},"y":{"field":"kappa","type":"quantitative"}},"data":{"values":"k,metric,kappa,mcc,accuracy\n13,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n7,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n9,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n4,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n10,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n5,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n15,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n3,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n6,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n11,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n12,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n14,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n2,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n1,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n8,euclidean,0.9333333333333332,0.9361080170496191,0.9555555555555556\n","format":{"type":"csv"}}},{"mark":{"type":"circle","size":50,"tooltip":true},"encoding":{"x":{"field":"k","type":"quantitative"},"y":{"field":"kappa","type":"quantitative"}},"data":{"values":"k,metric,kappa,mcc,accuracy\n13,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n7,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n9,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n4,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n10,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n5,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n15,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n3,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n6,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n11,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n12,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n14,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n2,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n1,euclidean,0.9665924276169264,0.9673116176179397,0.9777777777777777\n8,euclidean,0.9333333333333332,0.9361080170496191,0.9555555555555556\n","format":{"type":"csv"}}}],"height":300,"data":{"url":"assignments.hw2.q1_files\/0.csv","format":{"type":"csv"}}});</script></div>
```


This code creates a plot of the elbow method results for the Euclidean distance metric, showing how kappa changes with different K values.

> <span style="color: black; font-size: 1.5em;">**Looking at our elbow plot, we can see that the elbow dips down at $K=8$. Therefore, we want a K before 8. To me, 1 is too small and even numbers won't necessarily have a majority in a vote. I'd say good choices are 3, 5, or 7. I'll choose 5 because it's the middle value.**</span>

***3) Explore different distance metrics and repeat part 2 with another distance metric. In the report, justify the value of K and the distance metric.***


::: {.sourceClojure}
```clojure
(let [data (tc/select-rows results-dataset (comp #(= % "manhattan") :metric))]
  (-> data
      (haclo/layer-line {:=x :k :=y :mcc})
      (haclo/layer-point {:=x         :k :=y :mcc
                          :=mark-size 50})))
```
:::



```{=html}
<div><script>vegaEmbed(document.currentScript.parentElement, {"encoding":{"x":{"field":"x","type":"nominal"},"y":{"field":"y","type":"nominal"}},"usermeta":{"embedOptions":{"renderer":"svg"}},"width":400,"background":"floralwhite","layer":[{"mark":{"type":"line","tooltip":true},"encoding":{"x":{"field":"k","type":"quantitative"},"y":{"field":"mcc","type":"quantitative"}},"data":{"values":"k,metric,kappa,mcc,accuracy\n8,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\n3,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\n5,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\n2,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\n7,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\n10,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\n4,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\n9,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\n1,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\n12,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\n6,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\n11,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\n14,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\n15,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\n13,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\n","format":{"type":"csv"}}},{"mark":{"type":"circle","size":50,"tooltip":true},"encoding":{"x":{"field":"k","type":"quantitative"},"y":{"field":"mcc","type":"quantitative"}},"data":{"values":"k,metric,kappa,mcc,accuracy\n8,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\n3,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\n5,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\n2,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\n7,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\n10,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\n4,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\n9,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\n1,manhattan,0.9665924276169264,0.9673116176179397,0.9777777777777777\n12,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\n6,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\n11,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\n14,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\n15,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\n13,manhattan,0.9333333333333332,0.9361080170496191,0.9555555555555556\n","format":{"type":"csv"}}}],"height":300,"data":{"url":"assignments.hw2.q1_files\/1.csv","format":{"type":"csv"}}});</script></div>
```



::: {.sourceClojure}
```clojure
(let [data (tc/select-rows results-dataset (comp #(= % "cosine") :metric))]
  (-> data
      (haclo/layer-line {:=x :k :=y :mcc})
      (haclo/layer-point {:=x         :k :=y :mcc
                          :=mark-size 50})))
```
:::



```{=html}
<div><script>vegaEmbed(document.currentScript.parentElement, {"encoding":{"x":{"field":"x","type":"nominal"},"y":{"field":"y","type":"nominal"}},"usermeta":{"embedOptions":{"renderer":"svg"}},"width":400,"background":"floralwhite","layer":[{"mark":{"type":"line","tooltip":true},"encoding":{"x":{"field":"k","type":"quantitative"},"y":{"field":"mcc","type":"quantitative"}},"data":{"values":"k,metric,kappa,mcc,accuracy\n10,cosine,1.0,1.0,1.0\n12,cosine,1.0,1.0,1.0\n14,cosine,1.0,1.0,1.0\n6,cosine,1.0,1.0,1.0\n15,cosine,1.0,1.0,1.0\n5,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\n4,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\n9,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\n8,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\n1,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\n3,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\n11,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\n2,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\n7,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\n13,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\n","format":{"type":"csv"}}},{"mark":{"type":"circle","size":50,"tooltip":true},"encoding":{"x":{"field":"k","type":"quantitative"},"y":{"field":"mcc","type":"quantitative"}},"data":{"values":"k,metric,kappa,mcc,accuracy\n10,cosine,1.0,1.0,1.0\n12,cosine,1.0,1.0,1.0\n14,cosine,1.0,1.0,1.0\n6,cosine,1.0,1.0,1.0\n15,cosine,1.0,1.0,1.0\n5,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\n4,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\n9,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\n8,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\n1,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\n3,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\n11,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\n2,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\n7,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\n13,cosine,0.9665924276169264,0.9673116176179397,0.9777777777777777\n","format":{"type":"csv"}}}],"height":300,"data":{"url":"assignments.hw2.q1_files\/2.csv","format":{"type":"csv"}}});</script></div>
```



**Justification for K value and distance metric:**

*1. Euclidean distance (default):*
     
   - Optimal K: $[3, 5, 7]$
   - This metric is suitable for continuous features and assumes all features contribute equally.
   - It works well when the relationship between features is linear.

*2. Manhattan distance:*
     
   - Optimal K: $[3, 5]$
   - This metric is less sensitive to outliers compared to Euclidean distance.
   - It's particularly useful when features are on different scales or when dealing with high-dimensional data.
     
*3. Cosine distance:*
     
   - Optimal K: $[6, 10, 12, 14, 15]$
   - This metric is useful for high-dimensional data where feature scaling is important.
   - It's particularly useful when the angle between data points is more important than their magnitude.

The choice between these metrics depends on the specific characteristics of the Iris dataset:

- If the features are on similar scales and have a roughly linear relationship, Euclidean distance might be preferred.
- If there are potential outliers or the features are on different scales, Manhattan distance could be more appropriate.
- If the data is high-dimensional and feature scaling is important, cosine distance might be the best choice.

> <span style="color: black; font-size: 1.5em;">**The optimal K value balances between overfitting (low K) and underfitting (high K). The choice of distance metric depends on the specific characteristics of the dataset. Euclidean distance is a fine choice for this dataset for reasons explained above as well as being the easiest to understand. As such, I'd probably choose $K=5$ using the Euclidean distance metric.**</span>

***4) Train the KNN model with the optimal K value and chosen distance metric on the combined train and validation sets.***


::: {.sourceClojure}
```clojure
(def train-val-data-bootstrapped
  (-> train-data
      (tc/concat val-data)
      (tc/split->seq :bootstrap {:seed 123 :repeats 25})))
```
:::


This code combines the training and validation data, then creates 25 bootstrap samples for robust model evaluation.


::: {.sourceClojure}
```clojure
(def final-model
  (let [pipelines (map create-pipeline [{:n-neighbors 5
                                         :weights     "distance"
                                         :metric      "euclidean"}])
        evaluations (evaluate-model pipelines train-val-data-bootstrapped)]
    (process-results evaluations)))
```
:::


Here we define the final model using the chosen hyperparameters (5 neighbors, Euclidean distance) and evaluate it on the bootstrapped data.


::: {.sourceClojure}
```clojure
(-> final-model first :lookup-table)
```
:::



::: {.printedClojure}
```clojure
{"Versicolor" 0, "Setosa" 1, "Virginica" 2}

```
:::


This line retrieves the lookup table from the final model, which maps categorical labels to numerical values.

***5) Evaluate the model on the test set and report the accuracy.***


::: {.sourceClojure}
```clojure
(defn actual
  [model]
  (-> test-data :variety vec))
```
:::



::: {.sourceClojure}
```clojure
(defn preds
  [model]
  (let [lookup-table (-> model first :lookup-table)
        reverse-lookup (zipmap (vals lookup-table) (keys lookup-table))]
    (-> test-data
        (morph/transform-pipe
         (-> model first :pipe-fn)
         (-> model first :fit-ctx))
        :metamorph/data
        :variety
        (->> (map #(get reverse-lookup (long %)))
             vec))))
```
:::


These functions extract the actual labels from the test data and generate predictions using the trained model, respectively.


::: {.sourceClojure}
```clojure
(defn evaluate-predictions
  "Evaluates predictions against actual labels, returns confusion map and metrics."
  [preds actual]
  (let [conf-map (mlc/confusion-map->ds (mlc/confusion-map preds actual :none))
        accuracy (loss/classification-accuracy preds actual)
        kappa (stats/cohens-kappa preds actual)
        mcc (stats/mcc preds actual)]
    {:confusion-map conf-map
     :accuracy      (format "%.4f" accuracy)
     :cohens-kappa  (format "%.4f" kappa)
     :mcc           (format "%.4f" mcc)}))
```
:::


`evaluate-predictions` calculates various performance metrics including accuracy, Cohen's kappa, and Matthews correlation coefficient, along with a confusion matrix. At last, we generate predictions on the test set, compare them with the actual labels, and compute the evaluation metrics to assess the model's performance.


::: {.sourceClojure}
```clojure
(let [preds (preds final-model)
      actual (actual final-model)]
  (evaluate-predictions preds actual))
```
:::



```{=html}
<div><p>{</p><div class="clay-map" style="margin-left:10%;width:110%;"><table><tr><td valign="top"><div><pre><code class="sourceCode language-clojure printed-clojure">:confusion-map
</code></pre></div></td><td><div style="margin-left:10px;"><div class="clay-dataset"><p>_unnamed [3 4]:</p><table class="table"><thead><tr><th>:column-name</th><th>Setosa</th><th>Versicolor</th><th>Virginica</th></tr></thead><tbody><tr><td>Setosa</td><td>5</td><td>0</td><td>0</td></tr><tr><td>Versicolor</td><td>0</td><td>5</td><td>0</td></tr><tr><td>Virginica</td><td>0</td><td>1</td><td>4</td></tr></tbody></table></div></div></td></tr></table><div><pre><code class="sourceCode language-clojure printed-clojure">:accuracy &quot;0.9333&quot;</code></pre></div><div><pre><code class="sourceCode language-clojure printed-clojure">:cohens-kappa &quot;0.9000&quot;</code></pre></div><div><pre><code class="sourceCode language-clojure printed-clojure">:mcc &quot;0.9061&quot;</code></pre></div></div><p>}</p></div>
```



::: {.sourceClojure}
```clojure
(answer (str "Accuracy on the Iris test set: "
             (get-in (let [preds (preds final-model)
                           actual (actual final-model)]
                       (evaluate-predictions preds actual))
                     [:accuracy])))
```
:::


> <span style="color: black; font-size: 1.5em;">**Accuracy on the Iris test set: 0.9333**</span>

***6) Provide a brief analysis of the results in your report.***

### Analysis of Results:

#### 1. Data Split: 
  We used a 70/20/10 split for train/validation/test, which is a common practice. This split provides enough data for training while reserving sufficient data for validation and testing. However, the Iris dataset is small, where the 10% holdout is just 15 samples.

#### 2. Elbow Method: 
  This approach effectively determined the optimal K value, balancing between model complexity and performance, between underfitting and overfitting.

#### 3. Distance Metrics:
  Comparison of Euclidean and Manhattan distances revealed metric-dependent optimal K values, underscoring the importance of metric selection in KNN.

#### 4. Final Model:
  We selected Euclidean distance with K = 5, based on the elbow method results. This choice aims to balance model simplicity with performance.

#### 5. Model Performance:
  The final accuracy of $0.9333$ on the test set demonstrates strong generalization to unseen data, validating our K and distance metric choices.

#### 6. Limitations and Future Work:
  
  - Explore additional distance metrics and feature scaling techniques for potential performance improvements.
  - Implement k-fold cross-validation for more robust performance estimation.
  - Conduct feature importance analysis to identify key iris characteristics for classification.
  - Consider testing the model on a larger, more diverse dataset to assess its broader applicability.


```{=html}
<div style="background-color:grey;height:2px;width:100%;"></div>
```



```{=html}
<div></div>
```
